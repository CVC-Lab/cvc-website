{
    "componentChunkName": "component---src-pages-markdown-remark-frontmatter-slug-js",
    "path": "/projects/search-n-score/",
    "result": {"data":{"markdownRemark":{"html":"<h2>Project Introduction</h2>\n<p>Rapid search (detection &#x26; localization) and full recognition (classification with ranking and scoring) in ultra-high resolution giga-pixel images has been hampered by the sheer size of the image \"haystack\". Moreover, informative features (aka. needles) for recognition need to be discerned at multiple zoom levels, permissible due to the ultra-high image resolution. Applications that routinely generate andrequire search and recognition giga-pixel images include digital pathology based on ultra-scanned stained tissue biopsies (aka. Whole Slide Images (WSIs) that are typically 100K pixels Ã— 100K pixels), and wide-area and panoramic surveillance including whole earth remote sensing (5 - 7 Gigapixel images with different aspect ratios). Digital pathology systems that are based on WSIs require full recognition (i.e., classification with Gleason scoring and ranking). In this paper, we develop a Multi-Agent Reinforcement Learning (MARL) framework for rapid search-and-score of giga-pixel images. Instead of exhaustively processing WSIs at the finest zoom detail, our RL method learns to optimally select patches of the WSI, and score them. Additionally the master agent trains slave agents to learn a task driven policy for statistically image processing the patches at the minimal required zoom level, and within a pre-defined uncertainty.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/e498d58efba2531809a7c245bdc650c5/60b3a/marl_diagram.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 55.00000000000001%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAADBElEQVQoz01TaUhUURT+3pvnvBmNnEotKpxSjEJEs8xCR9sgizKsIIqgqCgpScysaCeLEPoRZAhJSZuRK2ZpKq1ubepspk5p1mQzaTEzyrjMduKOGt0/955zz3fP+c75LqiN8JQIH5pbkXYkTQqAX7EgWppzMYcHgKDpQWzDwjmhICKQh5jJ7gQAEmbY2xxYFLoQMZFLAZq/ywtgwQCkqxPXzgMwdcL+tx7nF3B3sgsk2AyEzpznD2B2wIyAaWQh7hhW8UXHbvPnwrcBF2UK+QmAJyI/9+DwXsvXgffG+u7sJ2VV80Vf0W+WPJDbkJjA7mEqN4IwnpgVz3yDhT1QIxXm3M7xzNfFucodgNTpcF12O13kHB2zW7oHyKTtrX39sUkxWSkRBTVfrblcnVVSU3WocJ1v9HJhiJzBDVefX6vNLC5/nl6ybNXNsxLs4QVxNCJKPnJgp2i32bdYv/16NTYyfPxFaaU8mVHNuubj7Z3NdrRf3UufK7T0taZTfS/zmYKczjMD+p/UU6klQ7X+ZV52sT/OhyhFBtC+UUe212mX9Lb2xLXX6deZu02X6s/eCQwDBGXmRj4DkNjsxjUmMp/8OfbFn2HuAoLJ8SO5n6wZRBaZl03uzGAFm1ifoTbBbmreOmSsWzlk1mYMW/t0b9XNASwoLjbGJ2jNDskEfTZZIThVKcOlEHaWsan303fEL1dJcFOmnCsH/H63NIbTp1bVaJcm1tPRqrKp36pY8xWCTOITOEUgMoAWEfACMjYY391+YuQ+fz7xdIJvXnGeFONi4nF/U5K3VGtLS7pb354/9qX7ikuvz3V1dOYw/9qk9Xw8IKGUCHnFqaKURxceXL+1ID2E4aNykzj5doGTZomT6uKhPnh4XBINDWFunS56xNAV7tBookZ1uogbhw+hrKzUS9XjcaWa24ykyW+ijofveroKqpXqgnJQpZXDEgDixIMf0tO8ojY3NsKt02HEYIBDo4FDr/dGJKhUHADO5iApEe0np6PEY/mzePIzFJcX/q9/7i9Mu4lqRGmV/wAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Introduction\"\n        title=\"Introduction\"\n        src=\"/static/e498d58efba2531809a7c245bdc650c5/5a190/marl_diagram.png\"\n        srcset=\"/static/e498d58efba2531809a7c245bdc650c5/772e8/marl_diagram.png 200w,\n/static/e498d58efba2531809a7c245bdc650c5/e17e5/marl_diagram.png 400w,\n/static/e498d58efba2531809a7c245bdc650c5/5a190/marl_diagram.png 800w,\n/static/e498d58efba2531809a7c245bdc650c5/60b3a/marl_diagram.png 1179w\"\n        sizes=\"(max-width: 800px) 100vw, 800px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>An illustration of the proposed MARL pipeline. <strong>Left:</strong> Scanning search is performed on input giga-pixel image by SA. Patches are identified and concurrently operated on by DAs. <strong>Right:</strong> A single trajectory of DA is illustrated. DA selects sub-regions from observed region belonging to the patch indexed. DA terminates returning select representations of characteristic patterns (e.g., select information mask, topological or structural information etc.). Next state of the SA, composed of patch-location, score matrix and optimal representation, is used by SA in identifying next set of patches for scheduling or in deciding to terminate the search returning score.</p>\n<h2>Rank-ordered Search-and-Score</h2>\n<p>We target the challenging family of problems where information categories (i.e, entity components and their sub-components) that make up the tasks' <em>rank-ordered rubric</em> are ranked by importance. Furthermore, entities are hierarchical spanning multiple levels of scale and sparsely distributed within a large search space. Generally speaking, such problems are characterized by higher-ranked categories more sparse than lower-ranked categories. They stress the importance of performing efficient search and the possibility of exploiting underlying structure of the scoring rubric for prioritized search. For example, in the medical domain of pathology, irrelevant information or noise occupies majority of the search space (e.g., slide background in whole slide tumor scan images. As a result, the distribution of information categories associated with the task-dependent scoring scheme in rank-ordered search problems are highly imbalanced. Based on categorization of task-dependent scores and memory limitations dictating maximum observable information of the search space, an attempt to rapidly perform rank-ordered search and score will have to: (1) identify and capture inter-dependence of hierarchically distributed features; and (2) learn a sample efficient search strategy that exploits patterns in the data distribution for rank-ordered search.</p>\n<h2>MARL Search-and-Score</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/6681e0082f8c67bb160e72ce651596dc/d3d45/sched_dp.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 43.99999999999999%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAACrklEQVQozzWQW0jTARjFzzZvKbot7yUSCVaGZJFYD5bQSz3UQ5YPRaj1YkJiIQnqSxDeIJsKopmBYxqhmWnmBs55aSrsv83/3F23tXlLy0u4qSv1i7/QB+fl8PsOh4MZgz9rddXnkknZeCBbcCmLgsvLNkOJ3HA4vJWLi9738/O72T9XvHoiwn9tetXwbamxujyQ2/qm7AIAYUREWBQM2p1oj3khe0RRn+JbkL/SqAdzHE6PlHuanvanmc1bmYsr/ninZe3a3Ghdxt6asnpEIUu1WMxSDesMM2nkuVUvSi8DiDoqFopA+xsh+w5zZkXtTdGKrfPi6HDPOS3DFJFGFlKRcyAg8kD50YW/ROiuK0nwGDoyBno7jjOMpnZQqw3xyj4kNhcVRwIIihOLA0A+4tlcU6Lz2WdDuFYdnZ8S9AyTQxZj5rx2KQkgPhADtk4SCoDPMTWSpnCWNdzeW/8lAMApPFDAFwIIBvOt9HCTZnlNnHpW9XhoXJ65tLT8nPMe5FHAk8LtIGDnkJluajztGxt+2N/Zkeh0OktmWDac819XVvMBIFIkArrU7WhRStDSKxErLIN5fareLKvFWnWwT2h4S0H3CygQIKx/7Ya2rTXpx0B/4cC7tmS9Tlc/bbUKe4ZV2PXvcHngB3DoBCF34i5oi3ikn022Mroc+6x9aFwxIj4GCih/9PtIMWp45FoCjQ5hW8dgymgUMhrN0+3JyTTyeNLJ7ca2ycQDeIDPxMA+0g6bSc+n73PxMzr2qmPOIXl2Q5p4PbYqNj9FGn3r5MsTV07dg6pRxiNWx7ebzQKTwRD7R6UKJrc7iGw2kNV62BJkNIJUwxj7ouFbx1iMf2EKJuRaU1t11xkgRpSf2hBRl74RSEWEO5BD3vcZdpcLrE4Hv1IJrh3Z7eBCufsHtvOFhwgzjgQAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"SA\"\n        title=\"SA\"\n        src=\"/static/6681e0082f8c67bb160e72ce651596dc/5a190/sched_dp.png\"\n        srcset=\"/static/6681e0082f8c67bb160e72ce651596dc/772e8/sched_dp.png 200w,\n/static/6681e0082f8c67bb160e72ce651596dc/e17e5/sched_dp.png 400w,\n/static/6681e0082f8c67bb160e72ce651596dc/5a190/sched_dp.png 800w,\n/static/6681e0082f8c67bb160e72ce651596dc/c1b63/sched_dp.png 1200w,\n/static/6681e0082f8c67bb160e72ce651596dc/29007/sched_dp.png 1600w,\n/static/6681e0082f8c67bb160e72ce651596dc/d3d45/sched_dp.png 1614w\"\n        sizes=\"(max-width: 800px) 100vw, 800px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>At each time step, patch location set is predicted. SA transitions to state constructed from patch location, label, and pattern characterization representation returned by DA. Otherwise, SA may terminate search based on the state and produce a score. Negative reward is received, reflecting the computational cost of performing drill search on these patches and a positive reward if predicted score matches ground truth.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/10d7fb45aebe18fdec662398d1b43add/b54cd/drill_dp.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 37%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAACMElEQVQozz3OW0hTARzH8X/q1EVLm7RKCJcGrQve6FWJihqDSmRKSAjrIj1lSb6UvbUu1ENlPVRkEkFgudg8u9rm2TlnF92ca2s723EXd4npMidN60X5xxr0e/7y4QeIC5BO5F/GYlnlyKN7u/QqS4PDmWk50RbiRyKrz9Pp9evJVH4gGVt6anshEbCu93u8/kBtfD4nWsgYGq2O0Q4A2LpTJBQCQClgnDs8o6Rq5NfGhH8yxNXl6OcrnjnvcDQVawRAUKvWhIhYIa8b5Oe4T5c2l/UKhrb2sRx3I2sl6o3vXncDgLBKsK0WAPiAsbAYEaHv4ch2AKgEgBLGbr+w6Ha2rnuTEkSAJ7do6AcobWsQVxdahqal066ZDn02BfhGzZPt3Q//t+JJwehbLB98/KH6pvJizelzp0TfAsGz2VnnwUVnqk7W/ZtXQJTtxyt0Q7d3nG9uFrjc7kMhlm1x0Q4YRgQJlACUlxZBRGIL4itAXAMmbr5sDOh6/X7/3UgidgRXvVB4GKXCUEAXCU3vCqHuIUmyJ8yyA8iyrQmzuSx/Zwg2SLIIzlHz4KU4hcMYkn4PUvUR0tg045zuX8olRLOWcJfH4JNjOnIgHf9Z5tOoRTmSPPpFq5XaGEbhNJm6CJOJ/3FiArRabRH028Lgo0Od7qlAO/5aFqDHt9tOMycfPLtfZRizdDo0NhlmkuIfX4M83NjkIcfts09ONtns9mNWijqj0+kqVePjQBDEP/AvnHcvfL3y3KEAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"DA\"\n        title=\"DA\"\n        src=\"/static/10d7fb45aebe18fdec662398d1b43add/5a190/drill_dp.png\"\n        srcset=\"/static/10d7fb45aebe18fdec662398d1b43add/772e8/drill_dp.png 200w,\n/static/10d7fb45aebe18fdec662398d1b43add/e17e5/drill_dp.png 400w,\n/static/10d7fb45aebe18fdec662398d1b43add/5a190/drill_dp.png 800w,\n/static/10d7fb45aebe18fdec662398d1b43add/c1b63/drill_dp.png 1200w,\n/static/10d7fb45aebe18fdec662398d1b43add/29007/drill_dp.png 1600w,\n/static/10d7fb45aebe18fdec662398d1b43add/b54cd/drill_dp.png 1662w\"\n        sizes=\"(max-width: 800px) 100vw, 800px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>At each zoom action, a region is selected for observation. Each selection receives a negative reward reflecting the computational cost of sampling. Otherwise, DA may terminate search and representations of characteristics is returned to SA.</p>\n<h2>HRL Search-and-Score</h2>\n<p><img src=\"\" alt=\"HRL Pipeline\"></p>\n<h2>Results</h2>\n<h3>MARL Search-and-Score</h3>\n<p><img src=\"\" alt=\"MARL performance\"></p>\n<h3>HRL Search-and-Score</h3>\n<p><img src=\"\" alt=\"HRL performance\"></p>\n<h2>Project Members</h2>\n<p><a href=\"https://rochan-a.github.io\">Rochan Avlur Venkat</a>, Conrad Li, Kartikeya Badola, Priyansh Kedia, <a href=\"https://www.cs.utexas.edu/~bajaj/\">Dr. Chandrajit Bajaj</a></p>\n<h2>Code Repo</h2>\n<p><a href=\"https://github.com/CVC-Lab/mvrl-wsi-pathology/\">Github link</a></p>\n<h2>Paper(Under preperation)</h2>\n<p><a href=\"\">Active Learning of Multi-Agents to Rapidly Search and Score Giga-Pixel Images</a></p>\n<p><a href=\"\">Towards Hierarchical Annotation of Prostate Cancer Whole Slide Images</a></p>","frontmatter":{"title":"Rapid Rank-ordered Search-and-Score"}}},"pageContext":{"id":"9b6b4d2d-17a4-50a1-aa15-520c4fb095d8","frontmatter__slug":"/projects/search-n-score","__params":{"frontmatter__slug":"projects"}}},
    "staticQueryHashes": ["2105308271"]}