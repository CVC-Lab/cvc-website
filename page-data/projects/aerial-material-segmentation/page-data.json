{"componentChunkName":"component---src-pages-markdown-remark-frontmatter-slug-js","path":"/projects/aerial-material-segmentation/","result":{"data":{"markdownRemark":{"html":"<p><strong>By Chandrajit Bajaj, Minh Nguyen, and Shubham Bhardwaj</strong></p>\n<p><span class='gatsby-resp-image-wrapper' style='position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; '>\n      <a class='gatsby-resp-image-link' href='/static/fbb62035ec691b4ade6636ffafdf7c7d/0ddab/aerial_model.png' style='display: block' target='_blank' rel='noopener'>\n    <span class='gatsby-resp-image-background-image' style=\"padding-bottom: 70%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAABYlAAAWJQFJUiTwAAACDklEQVR42pVTPWsUURQdLIX8BRs7f4NdGjWFXcBGsEpnY20r/gHBQgUNLiRNEAIBs1aKhV3WLGY3u9Hs7Ex2ZnbnzfeHWTm+85Y7LAmKFod5b+a9c8+954wVRRGCmULgh/D9AEmSIssyzGYzRGmFIqsQxRHiOEaapn8F71llXkKdncD1uqjOc1RVgel0ChUnyE4/oH/YRq4Sc7goigZ5npt3BNcC6+DTPh4/uosH6y/w9OEx+l0H5fwcYecLhq9vYb91E9ub9+GedFFUP3UHC6VUHIahAfcN4dabZ7CuXsP1lSdYvdHC3ruvqH/VONjbQntnF732W3xsbWB49Bmpbj/W7XNMJCEZRyMqqdwaHndwe+0erlhrWL/zCoP+GRzHRn8wwFHvFN96Nn5892DbY0wmE6NMKWUQBAE8z9OqEwN+s+q6RqLn9fL5exx2bMy1OqUiU7Esc31QaTWxUUUS3/c1uW3IHcfBeDxezFx/o1pL5ANzbUiuqyRmn+hqrCjVCXGTxcRVWTcu8yAVBcHUVFi++L9oCDkLyifhotWywXJM/gUWmXmRrY9GI0NMcM2Bm+DrgmxfsrecwUs5JCEVSKZ4mUrFQa45cBKLUhFxMegNIRdiu8SChHSUDvIdn4T5JTW567oG7IaOXyIUsBrboDoeJLFEhhGjMinOd/KPN4R/clUis7wnscTs4hzF5d95lRFzXfbTnQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class='gatsby-resp-image-image' alt='image' title='' src='/static/fbb62035ec691b4ade6636ffafdf7c7d/5a190/aerial_model.png' srcset='/static/fbb62035ec691b4ade6636ffafdf7c7d/772e8/aerial_model.png 200w,\n/static/fbb62035ec691b4ade6636ffafdf7c7d/e17e5/aerial_model.png 400w,\n/static/fbb62035ec691b4ade6636ffafdf7c7d/5a190/aerial_model.png 800w,\n/static/fbb62035ec691b4ade6636ffafdf7c7d/c1b63/aerial_model.png 1200w,\n/static/fbb62035ec691b4ade6636ffafdf7c7d/29007/aerial_model.png 1600w,\n/static/fbb62035ec691b4ade6636ffafdf7c7d/0ddab/aerial_model.png 2220w' sizes='(max-width: 800px) 100vw, 800px' style='width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;' loading='lazy' decoding='async'>\n  </a>\n    </span></p>\n<h3><strong>Introduction</strong></h3>\n<p>Material segmentation, especially in night-time aerial environments, is a challenging task due to poor lighting conditions and atmospheric disturbances. Traditional RGB imaging methods struggle in such environments, which is where hyperspectral imaging (HSI) technology comes into play. However, the high cost and low spatial resolution of hyperspectral cameras limit their usage. Our project introduces a low-cost solution for robust material segmentation using a novel framework that fuses hyperspectral data with RGB imagery, ensuring efficient segmentation in challenging night-time conditions.</p>\n<hr>\n<h3><strong>Problem Statement</strong></h3>\n<p>Hyperspectral cameras capture the electromagnetic spectrum in many continuous bands, providing rich spectral information for tasks like material segmentation. However, due to hardware limitations, high spectral data comes at the cost of spatial resolution. Furthermore, incorporating this high-dimensional data into learning-based models adds computational complexity. Our research addresses this by creating a scalable framework that integrates hyperspectral and RGB data, reducing the need for expensive hardware without compromising performance.</p>\n<hr>\n<h3><strong>Key Contributions</strong></h3>\n<ol>\n<li><strong>Selective Channel Utilization:</strong> Instead of processing the entire hyperspectral dataset, we employ time-series analysis to extract essential spectral channels, significantly reducing computational overhead.</li>\n<li><strong>Siamese Deep Learning Architecture:</strong> Our innovative Siamese network processes both hyperspectral and RGB data, combining them for robust segmentation.</li>\n<li><strong>Robust Performance in Adverse Conditions:</strong> The model is specifically designed to operate in low-light and atmospheric disturbances, outperforming traditional methods in difficult conditions.</li>\n</ol>\n<hr>\n<h3><strong>Methodology</strong></h3>\n<p>Our approach leverages hyperspectral and RGB image pairs for the segmentation task. By employing time-series-based compression, we reduce the number of spectral channels and retain only the most informative data points. This is followed by a Siamese network that merges the reduced hyperspectral data with RGB data to predict pixel-level material segmentation.</p>\n<p><span class='gatsby-resp-image-wrapper' style='position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; '>\n      <a class='gatsby-resp-image-link' href='/static/916c888686c8c7c1574c5d305aea0e60/636d3/aerial_plot.png' style='display: block' target='_blank' rel='noopener'>\n    <span class='gatsby-resp-image-background-image' style=\"padding-bottom: 62%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAACZElEQVR42k1T226bQBD1//9IXyv1pS9VpbZOUiVpUl+xF2PDcjEYGy+XBS/g0xnSukEaMRrtnJ1zzuwI9DVNg9a06Lsefd/j/VeWBbSuhnrXdUNwrrVGEITwfZ/+AaIoorMlRm3bDkl5KaFMDhlLCM+GTSETH5PZPTab9a1ZSokwjLBaLWFZC9j2Bo7jQCkFxhrxbU3dICkPkIWP39sJxtM7jCd3eBYveHz9ipU1J1CHmm0IYROAwGzmY7mMhssY0PO8YeobYKqP8JTEvoqR1AckzQGRTpBkO+iqIKr9MIEhaXBtEcYGlkgJcAXXdZEkCfI8x8i0hhqqAVAqoqQCeGfSpZAIygD7k4UiT0lnTROUqAjckObytMV8N8WWJo+icND7crlgxNzZlLTiCRmIBK58iDjAwg8hHBtxdMY5M1BZgzyrkakOhUNsplOa0sHhkP4HNMYM3BnQp6ksEv9hssf3lwxP4oif0w0WdgwnLLHbK7jxGSLMsZcx4t0Ws6XAZitxSDPUNWnY9R0l9U1Dv4ixUXvcr79g5o4x/vUBC+sbTfoEsXmEJJqRO0d28pGeEqzJbc9j2j6y7PxmCgMmZQovD7GUr7h//gjx4xNc6xH+w2cU8xkaWo9mLWDWNowl0AQRdE47SkZUKocuCtQk3bCHTLlochyNQupZyFwL507j1JVIySBVKui2Q0XyVO1baNJL13ro5WAfBg1ZzLqpYS4G1/46REsy9PQiQHl2Smlpz/SSDGpq5GiIUf0OiBly7QbIxrDbXOAD+V/nuZ4zLWo8Ho/4txHMqqJV4+CcAfm18Uv5Az8Hh5ijP8McAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class='gatsby-resp-image-image' alt='image' title='' src='/static/916c888686c8c7c1574c5d305aea0e60/5a190/aerial_plot.png' srcset='/static/916c888686c8c7c1574c5d305aea0e60/772e8/aerial_plot.png 200w,\n/static/916c888686c8c7c1574c5d305aea0e60/e17e5/aerial_plot.png 400w,\n/static/916c888686c8c7c1574c5d305aea0e60/5a190/aerial_plot.png 800w,\n/static/916c888686c8c7c1574c5d305aea0e60/c1b63/aerial_plot.png 1200w,\n/static/916c888686c8c7c1574c5d305aea0e60/636d3/aerial_plot.png 1222w' sizes='(max-width: 800px) 100vw, 800px' style='width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;' loading='lazy' decoding='async'>\n  </a>\n    </span></p>\n<hr>\n<p><span class='gatsby-resp-image-wrapper' style='position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; '>\n      <a class='gatsby-resp-image-link' href='/static/2f22c09ffe959b5040e255c73b0c6c1b/0d0e4/aerial_images.png' style='display: block' target='_blank' rel='noopener'>\n    <span class='gatsby-resp-image-background-image' style=\"padding-bottom: 43.50000000000001%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAABYlAAAWJQFJUiTwAAACGElEQVR42l1SyWvaURD+GeOCkrqgxEQsxUuhpG0KTWgIJC1pJFUjtj1YD+m1FPr3aFzAgxRM6XLykNzd4oI1tVWQ5hbQxGhccPerM9Ae+mB4M99838y8xwiFswKyZ9/x49dP/L64QOX8HOnTU8TjcaTTaeTzeZRKJaRSKcRiMcYKhQJjiUSCedlslnntdhvC2vpjmNbuY9O2iz33G7x8/QrLy8uYn5/H4uIiDAYDbDYbNBoNBEHA0tISjEYjHA4HpFIpxGIxTCYTtFotNxVWVx/OCq5gw7KF9adbsL7YY5FMJuWCCwsLsFqtUKvVLCZMr9djf38fEolkxpMxn3jJZBLCtmUH92w7ePRsE9uW53j34T1uzzqqVCqeijq7XC4uIpfLOTabzXC73VAoFFAqldDpdDxlLpeDsGHdhf7JA9xZuYtbGjXcbw9YTM+jiei22+0sJl8kEmFubg5Op5Nj8snIz2QyEL58+4pQ5CMinz8hEAggGo0icnSEw8ND+Hw+eDwenJycIBQKwev18h0Oh3F8fAy/388cwoPBIK6uriCMRiP0ez0M+n30ZzadTjGZTED4YDDAeDxGb5av1WosGA6HoNPtdlGtVnF5ecl50tER6vU6J+lutVu4vr7+Z61Wiwvd3NxwTJz/84RRvtlsch2BPrJSqfBOlctlFItFXMz2sdPpsICI5DcaDfZp1/4aTUYcMuLQC/8AuGTbS4HhXyAAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class='gatsby-resp-image-image' alt='image' title='' src='/static/2f22c09ffe959b5040e255c73b0c6c1b/5a190/aerial_images.png' srcset='/static/2f22c09ffe959b5040e255c73b0c6c1b/772e8/aerial_images.png 200w,\n/static/2f22c09ffe959b5040e255c73b0c6c1b/e17e5/aerial_images.png 400w,\n/static/2f22c09ffe959b5040e255c73b0c6c1b/5a190/aerial_images.png 800w,\n/static/2f22c09ffe959b5040e255c73b0c6c1b/c1b63/aerial_images.png 1200w,\n/static/2f22c09ffe959b5040e255c73b0c6c1b/0d0e4/aerial_images.png 1230w' sizes='(max-width: 800px) 100vw, 800px' style='width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;' loading='lazy' decoding='async'>\n  </a>\n    </span></p>\n<h3><strong>Experimental Results</strong></h3>\n<p>Our framework was evaluated on well-known aerial datasets (Jasper Ridge and Urban), simulating adverse conditions like low light and atmospheric scattering. The results demonstrate significant improvements in segmentation accuracy compared to baseline models, with notable resilience to night-time conditions.</p>\n<p>Key findings:</p>\n<ul>\n<li><strong>Jasper Ridge Dataset:</strong> Achieved superior segmentation accuracy, with a 10% improvement over traditional U-Net and CNN models in low-light conditions.</li>\n<li><strong>Urban Dataset:</strong> Our model maintained robust performance even with heavy atmospheric scattering and low contrast, outperforming RGB-only methods.</li>\n</ul>\n<hr>\n<h3><strong>Conclusion</strong></h3>\n<p>We introduced a novel, low-cost solution for night-time aerial material segmentation using hyperspectral data and sparse spatio-temporal learning. Our method significantly reduces the need for expensive equipment while maintaining high performance in adverse environmental conditions. Future work will explore extending this framework to other domains and applications beyond material segmentation.</p>","frontmatter":{"title":"Low-cost Robust Night-time Aerial Material Segmentation through Hyper Spectral Data and Sparse Time Series Extraction"}}},"pageContext":{"id":"f5d03d3d-8992-545d-9482-88cb79d3ead7","frontmatter__slug":"/projects/aerial-material-segmentation","__params":{"frontmatter__slug":"projects"}}},"staticQueryHashes":["1689586968"],"slicesMap":{}}