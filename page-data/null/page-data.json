{"componentChunkName":"component---src-pages-markdown-remark-frontmatter-slug-js","path":"/null/","result":{"data":{"markdownRemark":{"html":"<!-- ---\ntitle: \"Dynamic Belief Games\"\nslug: \"/projects/dynamic-belief-games\"\ndate: \"2024-09-12\"\n---\n\n![Diagram](../../../images/projects/dynamic_belief_games/dynamic_belief_games_diagram.png)\n![drone-swarm.jpg](../../../images/projects/dynamic_belief_games/drone-swarm.jpg)\n*Figure: A visual of our DBG gym, demonstrating a drone swarm scenario.*\n\n## What are we trying to do?\n\nThe goal of this project is to develop Predictive Intelligent Networking (PIN) agents capable of rapid response decision-making in dynamic, adversarial communication networks. Our next-generation AI-trained PIN agents are designed to enhance their capabilities through continual field training with adversarial agents, leveraging a Dynamic Belief Games framework. This framework fosters learning across diverse interactions, where agents adapt to and optimize under various adversarial scenarios.\n\nOur approach aims to automate the setup and deployment of the primary, alternate, contingency, and emergency (PACE) communications plan, reduce overhead traffic, and improve scalability in sparse and challenging network environments.\n\n## What is the problem?\n\nIn dynamic communication networks, agents must continuously adapt to rapidly changing conditions and adversarial behavior. Network sparsity, unpredictable adversaries, and the challenge of maintaining efficient communication under constrained resources pose significant obstacles to efficient and secure communication.\n\n## Why is it hard?\n\nThe complexity arises from the dynamic nature of adversarial networks, where conditions can change rapidly, and agents must continually learn from interactions. Traditional methods of network optimization are insufficient to handle the dynamic and adversarial nature of these environments, requiring novel AI-driven approaches that can operate with incomplete and uncertain information.\n\n## How is it done today, and what are the limits of current practice?\n\nCurrently, network optimization is based on static models or fixed algorithms that cannot easily adapt to changes in network conditions or adversarial behavior. The limits of current practice include inefficiency in handling dynamic adversarial environments, high overhead traffic, and the inability to automate communications planning across varying conditions.\n\n## What we’re doing.\n\nOur approach involves developing and training AI-based PIN agents within the Dynamic Belief Games framework. These agents engage in adversarial interactions and cross-training to learn optimal action selection strategies that reduce traffic overhead, automate PACE communications planning, and enhance network scalability in complex terrains. By integrating machine learning with game theory, we are creating agents that can respond dynamically to adversarial threats and network conditions.\n\n## Hiring Opportunities\n\nOur Dynamic Belief Games (DBG) project was recently funded for three years, and we welcome candidates from various disciplines, including Mathematics, Physics, Computational Science, and Computer Science. We’re flexible with options for:\n\n1. Students interested in potentially continuing towards a Math Ph.D.\n2. Students with relevant qualifications interested in this as a side project.\n\nThe project is a blend of game theory, optimization, and optimally controlled Markovian decision processes for stochastic communication networks. This work is broadly applicable to predictive modeling in dynamical systems.\n\nCandidates with knowledge of cooperating/non-cooperating stochastic processes and experience minimizing empirical risk measures (stochastic functionals) are encouraged to apply. These measures are tailored for proactive maintenance and performance in stochastic communication networks.\n\n**We are also seeking MS and PhD graduate students to join our team. Interested candidates can email us directly at:**\n\n- **Ryan Farell:** ryan.farell@utexas.edu\n- **Chandrajit Bajaj:** bajaj@cs.utexas.edu\n\n### Postdoctoral Fellow\n\nThis role involves working on cutting-edge AI networking technologies under the guidance of Prof. Chandrajit Bajaj at the University of Texas at Austin. The position focuses on the development of PIN agents and advanced AI techniques for real-time decision-making in dynamic networks.\n[Apply Here](https://utaustin.wd1.myworkdayjobs.com/en-US/UTstaff/job/Postdoctoral-Fellow_R_00033359)\n\n### Software Engineer\n\nJoin our team to contribute to the development of advanced software solutions for AI-driven network optimization. This position will involve designing, implementing, and testing software systems for scalable, secure communication networks.\n[Apply Here](https://utaustin.wd1.myworkdayjobs.com/en-US/UTstaff/job/AUSTIN-TX/Software-Engineer_R_00033287?q=computer+science)\n\n### IT Network Security Specialist\n\nWe are seeking a security specialist to ensure the integrity and security of our AI-optimized networks. This role will involve managing network infrastructure and developing security protocols for predictive communication systems.\n[Apply Here](https://utaustin.wd1.myworkdayjobs.com/en-US/UTstaff/job/AUSTIN-TX/IT-Network-Security-Specialist_R_00033229?q=computer+science)\n\n### Announcement\n\nWe are also excited to share our upcoming training session on AI at the University of Texas. Check out the details [here](https://dra.utexas.edu/trainingAI).\n\n## Funding\n\nThis project is funded by the Army.\n\n## People\n\n- Chandrajit Bajaj (Principal Investigator) [(website)](https://www.cs.utexas.edu/~bajaj/cvc/index.shtml)\n- Ryan Farell (Lead Research Scientist) [(website)](https://rfarell.github.io/index.html)\n- Luke McLennan (PhD Student)\n- Aaron Dominick (PhD Student)\n- Matthew Kim (Technical Staff)\n -->","frontmatter":{"title":""}}},"pageContext":{"id":"3af5f2ae-7d07-5072-9ba8-3dfa5b648d7a","frontmatter__slug":null,"__params":{"frontmatter__slug":"null"}}},"staticQueryHashes":["39134446"],"slicesMap":{}}